{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b0f133c-27d5-4001-b9d6-02977fb9e190",
   "metadata": {},
   "source": [
    "Alejandra Gavino-Dias González"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab80d3b-d0a2-41d2-bb4a-4e1e273b8813",
   "metadata": {},
   "source": [
    "# Práctica 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08d9d32e-34d4-4ede-86e2-000d3008e891",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d432ade0-bcb5-4a2c-8055-7d7b1bce758c",
   "metadata": {},
   "source": [
    "### Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2498182-c5e6-4d03-bdba-53d654e6273f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optical_recognition_of_handwritten_digits = fetch_ucirepo(id=80) \n",
    "  \n",
    "X = optical_recognition_of_handwritten_digits.data.features\n",
    "y = optical_recognition_of_handwritten_digits.data.targets\n",
    "\n",
    "X = MinMaxScaler().fit_transform(optical_recognition_of_handwritten_digits.data.features)\n",
    "y = np.array(optical_recognition_of_handwritten_digits.data.targets).reshape(-1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7811750b-41a7-47fa-a77c-343256a90c2b",
   "metadata": {},
   "source": [
    "Preparamos el dataset para hacer Holdout y probar el funcionamiento del objeto RLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cf4e707-76aa-4c04-a400-2222038e32e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma de X_train: (3746, 64)\n",
      "Forma de X_test: (1874, 64)\n",
      "Forma de y_train: (3746,)\n",
      "Forma de y_test: (1874,)\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=1./3., random_state=20, stratify=y)\n",
    "print(\"Forma de X_train:\", X_train.shape)\n",
    "print(\"Forma de X_test:\", X_test.shape)\n",
    "print(\"Forma de y_train:\", y_train.shape)\n",
    "print(\"Forma de y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60037a37-937c-4f48-9a23-0de70ba20bef",
   "metadata": {},
   "source": [
    "## Ejercicio 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd680b16-4a6f-474b-8af6-37a901d11337",
   "metadata": {},
   "source": [
    "- **fit**: Método para ajustar el modelo a los datos de entrenamiento X e y. Utiliza OneHotEncoder para codificar la y en 0s y 1s. Luego, entrena un modelo de regresión lineal para cada clase utilizando los datos de características X y las etiquetas codificadas.\n",
    "- **predict**: Predecir las etiquetas de clase para nuevos datos test. Utiliza los modelos entrenados previamente con la función fit para generar las predicciones de probabilidad para cada clase y devuelve un vector codificado con 1 en la clase predicha y 0 en las demás.\n",
    "- **predict_proba**: Obbtenemos las probabilidades de predicción para cada clase utilizando la función softmax.\n",
    "- **score**: evalua el rendimiento de la predicción que se ha hecho, comparando las predicciones con la clasificación y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e79db0a-7716-4a4a-9826-a82594d58196",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class rlm:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.modelos = []\n",
    "        self.n_clases = None\n",
    "        self.predicciones = []\n",
    "        \n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.n_clases = len(np.unique(y))\n",
    "        deseada = OneHotEncoder(sparse_output = False).fit_transform(y.reshape(-1,1))\n",
    "        #salida deseada de cada clasificador lineal (LinearRegression)\n",
    "        for i in range(self.n_clases):\n",
    "            self.modelos.append(LinearRegression())\n",
    "            self.modelos[-1].fit(X, deseada[:,i])\n",
    "    \n",
    "    def predict(self, test):\n",
    "        salidas = np.zeros((test.shape[0], self.n_clases)) #creamos una matriz salidas y la inicializamos con 0s\n",
    "        for i, modelo in enumerate(self.modelos):\n",
    "            salidas[:, i] = modelo.predict(test) #iteramos sobre cada modelo y almacenamos la prediccion en salidas\n",
    "        self.predicciones = salidas\n",
    "        vector_codificado = np.zeros_like(salidas) #esto es porque la salida tiene que ser un vector de 0s y un 1 en el maximo\n",
    "        vector_codificado[np.arange(len(salidas)), np.argmax(salidas, axis=1)] = 1 #1 para la clase predicha\n",
    "        \n",
    "        return vector_codificado\n",
    "       \n",
    "    def predict_proba(self, pred):\n",
    "        from scipy.special import softmax        \n",
    "        salida = []\n",
    "        for p in self.predicciones:\n",
    "            salida.append(softmax(p))\n",
    "        return salida\n",
    "        \n",
    "    def score(self, X, y):\n",
    "        predicciones = np.argmax(self.predict(X), axis=1)  # Obtener las clases predichas\n",
    "        return np.mean(predicciones == y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95619ead-832b-4759-b955-a0329814586f",
   "metadata": {},
   "source": [
    "### Comprobación usando Holdout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f42f7e-00fa-4763-b937-d15378b3f4cf",
   "metadata": {},
   "source": [
    "X_train, X_test, y_train e y_test están definidas arriba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d07f0a0-d0ef-4b9f-9750-36c6c9ca37ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = rlm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf64ccd7-bb12-455d-ab68-32a75d4f3a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57a9e579-1656-4c4d-810d-9a1c5f88a292",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "vector=modelo.predict(X_train)\n",
    "print(vector) #solo para ver si es de la forma que queremos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9502490-e077-4fc2-ad7c-d13bdf9b499d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09879228 0.0901471  0.08273895 0.10382833 0.08080132 0.19950696\n",
      " 0.08662146 0.08201997 0.09881107 0.07673255]\n"
     ]
    }
   ],
   "source": [
    "probabilidades=modelo.predict_proba(vector)\n",
    "print(probabilidades[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a669055-b68b-4e8d-9e48-581bd3d83548",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.935965848452508\n"
     ]
    }
   ],
   "source": [
    "scores=modelo.score(X_test,y_test)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2326346-322a-4a55-b863-31a907b3bd84",
   "metadata": {},
   "source": [
    "## Ejercicio 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dee86d1-d9c4-432e-848b-4aa0ac35690d",
   "metadata": {},
   "source": [
    "Comparamos usando K-Fold con k=10 los métodos de regresión logística y regresión lineal múltiple. Obteniendo la tasa de aciertos al final para cada fold con 10000 iteraciones y una tasa de aciertos media para cada método para comparar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0b2ab53-3ce4-4e07-b2d1-27077a3979c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "c = StratifiedKFold(n_splits = 10, shuffle=True)\n",
    "rlm_lista = []\n",
    "rlog = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2ae9104-593c-4a16-a39e-e9df40380119",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de aciertos: RLM= 0.9217081850533808 \tRLOG= 0.9608540925266904\n",
      "Tasa de aciertos: RLM= 0.9252669039145908 \tRLOG= 0.9626334519572953\n",
      "Tasa de aciertos: RLM= 0.9341637010676157 \tRLOG= 0.9715302491103203\n",
      "Tasa de aciertos: RLM= 0.9466192170818505 \tRLOG= 0.9679715302491103\n",
      "Tasa de aciertos: RLM= 0.9395017793594306 \tRLOG= 0.9750889679715302\n",
      "Tasa de aciertos: RLM= 0.9377224199288257 \tRLOG= 0.9804270462633452\n",
      "Tasa de aciertos: RLM= 0.9359430604982206 \tRLOG= 0.9768683274021353\n",
      "Tasa de aciertos: RLM= 0.9359430604982206 \tRLOG= 0.9679715302491103\n",
      "Tasa de aciertos: RLM= 0.9341637010676157 \tRLOG= 0.9715302491103203\n",
      "Tasa de aciertos: RLM= 0.9306049822064056 \tRLOG= 0.9697508896797153\n",
      "\n",
      "Tasa de aciertos media: \n",
      "RML:  0.9341637010676157\n",
      "RLOG:  0.9704626334519573\n"
     ]
    }
   ],
   "source": [
    "for i_train, j_test in c.split(X, y):\n",
    "    X_train = X[i_train]\n",
    "    X_test = X[j_test]\n",
    "    y_train = y[i_train].ravel() #ravel: Return a contiguous flattened array (numpy)\n",
    "    y_test = y[j_test].ravel()\n",
    "    modelo = rlm()\n",
    "    modelo.fit(X_train, y_train)\n",
    "    rlm_lista.append(modelo.score(X_test, y_test))\n",
    "    \n",
    "    l = LogisticRegression(max_iter=10000)\n",
    "    l.fit(X_train, y_train)\n",
    "    rlog.append(l.score(X_test,y_test))\n",
    "    \n",
    "    print(\"Tasa de aciertos: RLM=\",rlm_lista[-1],\"\\tRLOG=\",rlog[-1])\n",
    "print(\"\\nTasa de aciertos media: \")\n",
    "print(\"RML: \", np.mean(np.array(rlm_lista)))\n",
    "print(\"RLOG: \",np.mean(np.array(rlog)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
